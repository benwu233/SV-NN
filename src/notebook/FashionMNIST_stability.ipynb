{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "p-PldpnA4COC",
    "outputId": "e601979b-4a3d-483f-d329-8e7ec00778cc"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "R[write to console]: Installing package into ‘/usr/local/lib/R/site-library’\n",
      "(as ‘lib’ is unspecified)\n",
      "\n",
      "R[write to console]: trying URL 'https://cran.rstudio.com/src/contrib/BayesGPfit_0.1.0.tar.gz'\n",
      "\n",
      "R[write to console]: Content type 'application/x-gzip'\n",
      "R[write to console]:  length 26941 bytes (26 KB)\n",
      "\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: \n",
      "\n",
      "R[write to console]: downloaded 26 KB\n",
      "\n",
      "\n",
      "R[write to console]: \n",
      "\n",
      "R[write to console]: \n",
      "R[write to console]: The downloaded source packages are in\n",
      "\t‘/tmp/RtmpYNvcgP/downloaded_packages’\n",
      "R[write to console]: \n",
      "R[write to console]: \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import argparse\n",
    "import random\n",
    "import time\n",
    "import os\n",
    "import warnings\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import rpy2.robjects as robjects\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "import torchvision\n",
    "\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from rpy2.robjects.packages import importr\n",
    "from torch.optim.optimizer import Optimizer, required\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "\n",
    "%matplotlib inline\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "## Install R package BayesGPfit\n",
    "\n",
    "utils = importr('utils')\n",
    "utils.install_packages('BayesGPfit', verbose = 0)\n",
    "GP = importr('BayesGPfit')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PZ-1rGV55FNH"
   },
   "source": [
    "## 1. Model\n",
    "\n",
    "### 1.1  BNNSTGP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "gV-55ma34w_u"
   },
   "outputs": [],
   "source": [
    "## BNNSTGP Model\n",
    "\n",
    "class BNNSTGP_two_layer(nn.Module):\n",
    "    def __init__(self, input_dim, n_hid, n_hid2, output_dim, w_dim, n_knots, phi, lamb=1.,\n",
    "                 b_prior_sig=1, zeta_prior_sig=1, eta_prior_sig=1, alpha_prior_sig=1,\n",
    "                 act='relu'):\n",
    "        super(BNNSTGP_two_layer, self).__init__()\n",
    "\n",
    "        self.input_dim = input_dim\n",
    "        self.n_hid = n_hid\n",
    "        self.n_hid2 = n_hid2\n",
    "        self.output_dim = output_dim\n",
    "        self.w_dim = w_dim\n",
    "        self.n_knots = n_knots\n",
    "        self.phi = phi  \n",
    "        self.lamb = lamb\n",
    "\n",
    "        self.sigma = nn.Parameter(torch.tensor(1.))\n",
    "        self.b = nn.Parameter(torch.Tensor(n_knots, n_hid).normal_(0, 1))\n",
    "        self.zeta = nn.Parameter(torch.Tensor(n_hid2, output_dim).uniform_(-1, 1))\n",
    "        self.eta = nn.Parameter(torch.Tensor(n_hid).zero_())\n",
    "        self.alpha = nn.Parameter(torch.Tensor(w_dim, output_dim).zero_())\n",
    "        self.fc = nn.Linear(n_hid, n_hid2)\n",
    "\n",
    "        self.b_prior_sig = b_prior_sig\n",
    "        self.zeta_prior_sig = zeta_prior_sig\n",
    "        self.eta_prior_sig = eta_prior_sig\n",
    "        self.alpha_prior_sig = alpha_prior_sig\n",
    "\n",
    "        if act == 'relu':\n",
    "            self.act = torch.relu\n",
    "        elif act == 'tanh':\n",
    "            self.act = torch.tanh\n",
    "        elif act == 'sigmoid':\n",
    "            self.act = torch.sigmoid\n",
    "        else:\n",
    "            raise ValueError('Invalid activation function %s' % act)\n",
    "\n",
    "    def forward(self, x, w):\n",
    "        out = torch.mm(self.phi, self.b)  ## beta_tilde, (p, n_hid)\n",
    "        out = F.threshold(out, self.lamb, self.lamb) - F.threshold(-out, self.lamb, self.lamb)  ## g_lambda\n",
    "        out = self.sigma * out\n",
    "        out = torch.mm(x, out) + self.eta  ## beta, (N, n_hid)\n",
    "\n",
    "        out = self.act(out)\n",
    "        out = self.fc(out)\n",
    "        out = self.act(out)\n",
    "        out = torch.mm(out, self.zeta)  # + torch.mm(w, self.alpha)\n",
    "\n",
    "        return out\n",
    "\n",
    "    def log_prior(self):\n",
    "        logprior = 0.5 * (self.b ** 2).sum() / (self.b_prior_sig ** 2)\n",
    "        logprior += 0.5 * (self.zeta ** 2).sum() / (self.zeta_prior_sig ** 2)\n",
    "        logprior += 0.5 * (self.eta ** 2).sum() / (self.eta_prior_sig ** 2)\n",
    "        logprior += 0.5 * (self.alpha ** 2).sum() / (self.alpha_prior_sig ** 2)\n",
    "        return logprior\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "af3T-9gU5YBo"
   },
   "source": [
    "### 1.2 SGLD "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "-0y0WaOQ5dDf"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "## SGLD (Stochastic Gradient Langevin Dynamics)\n",
    "\n",
    "class SGLD(Optimizer):\n",
    "    def __init__(self, params, lr = required, langevin = True):\n",
    "        self.langevin = langevin\n",
    "        defaults = dict(lr=lr)\n",
    "        super(SGLD, self).__init__(params, defaults)\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def step(self):\n",
    "        loss = None\n",
    "        \n",
    "        for group in self.param_groups:\n",
    "            \n",
    "            for p in group['params']:\n",
    "                if p.grad is None:\n",
    "                    continue\n",
    "                d_p = p.grad\n",
    "                \n",
    "                if self.langevin == True:\n",
    "                    langevin_noise = p.new(p.size()).normal_(mean=0, std=1)/np.sqrt(group['lr'])\n",
    "                    p.add_(0.5*d_p + langevin_noise, alpha = -group['lr'])\n",
    "\n",
    "                else:\n",
    "                    p.add_(0.5*d_p, alpha = -group['lr'])\n",
    "\n",
    "\n",
    "        return loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IAx3l4Nx5iR8"
   },
   "source": [
    "### 1.3 Network Wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "37tPkgQE5kaG"
   },
   "outputs": [],
   "source": [
    "\n",
    "## Network Wrapper\n",
    "\n",
    "## Network Wrapper\n",
    "class Net(object):\n",
    "\n",
    "    def __init__(self, task='binary', lr=1e-3, input_dim=784, n_hid = 128, n_hid2 = 64, output_dim = 1, w_dim = 1, n_knots = 66,\n",
    "                 N_train=200, phi=None, lamb = 1, langevin = True, step_decay_epoch = 100, step_gamma = 0.1, act = 'relu'):\n",
    "\n",
    "        # print(' Creating Net!! ')\n",
    "        self.task = task\n",
    "        if task not in ['binary', 'multiclass']:\n",
    "            raise ValueError('Invalid task %s' % task)\n",
    "        self.lr = lr\n",
    "\n",
    "        self.input_dim = input_dim\n",
    "        self.n_hid = n_hid\n",
    "        self.n_hid2 = n_hid2\n",
    "        self.output_dim = output_dim\n",
    "        self.w_dim = w_dim\n",
    "        self.n_knots = n_knots\n",
    "        self.phi = phi\n",
    "        self.lamb = lamb\n",
    "        self.act = act\n",
    "\n",
    "        self.N_train = N_train\n",
    "        self.langevin = langevin\n",
    "        self.step_decay_epoch = step_decay_epoch\n",
    "        self.step_gamma = step_gamma\n",
    "\n",
    "        self.create_net()\n",
    "        self.create_opt()\n",
    "        self.epoch = 0\n",
    "\n",
    "        self.weight_set_samples = []\n",
    "\n",
    "\n",
    "    def create_net(self):\n",
    "        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        self.model = BNNSTGP_two_layer(input_dim=self.input_dim, n_hid=self.n_hid, n_hid2=self.n_hid2, output_dim=self.output_dim,\n",
    "                                       w_dim=self.w_dim, n_knots = self.n_knots, phi=torch.tensor(self.phi).to(self.device),\n",
    "                                       lamb = self.lamb, act = self.act)\n",
    "        self.model.to(self.device)\n",
    "        # print('    Total params: %.2fK' % (self.get_nb_parameters() / 1000.0))\n",
    "\n",
    "\n",
    "    def create_opt(self):\n",
    "        self.optimizer = SGLD(params=self.model.parameters(), lr=self.lr, langevin = self.langevin)\n",
    "        self.scheduler = StepLR(self.optimizer, step_size = self.step_decay_epoch, gamma=self.step_gamma)\n",
    "\n",
    "\n",
    "    def fit(self, x, w, y, threshold=0.5):\n",
    "        x = x.to(self.device)\n",
    "        w = w.to(self.device)\n",
    "\n",
    "        if self.task == 'binary':\n",
    "            y = y.float().to(self.device).reshape(-1, 1)\n",
    "            self.optimizer.zero_grad()\n",
    "\n",
    "            out = self.model(x, w)\n",
    "            loss = F.binary_cross_entropy_with_logits(out, y, reduction='mean')\n",
    "            loss = loss * self.N_train\n",
    "            # loss += self.model.log_prior()\n",
    "\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "\n",
    "            pred = (torch.sigmoid(out ) >threshold).long()\n",
    "            accu = (pred == y.long()).sum().float()\n",
    "\n",
    "        else:                           ## multiclass\n",
    "            y = y.long().to(self.device).reshape(-1)\n",
    "            self.optimizer.zero_grad()\n",
    "\n",
    "            out = self.model(x, w)\n",
    "            loss = F.cross_entropy(out, y, reduction = 'mean')\n",
    "            loss = loss * self.N_train\n",
    "            loss += self.model.log_prior()\n",
    "\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "\n",
    "            pred = out.max(dim=1, keepdim=False)[1]\n",
    "            accu = (pred == y).sum()\n",
    "\n",
    "        return loss *x.shape[0 ] /self.N_train, accu\n",
    "\n",
    "\n",
    "    def eval(self, x, w, y, threshold=0.5):\n",
    "        x = x.to(self.device)\n",
    "        w = w.to(self.device)\n",
    "\n",
    "        if self.task == 'binary':\n",
    "            y = y.float().to(self.device).reshape(-1, 1)\n",
    "\n",
    "            out = self.model(x, w)\n",
    "            loss = F.binary_cross_entropy_with_logits(out, y, reduction='mean')\n",
    "            loss = loss * self.N_train\n",
    "            loss += self.model.log_prior()\n",
    "\n",
    "            pred = (torch.sigmoid(out ) >threshold).float()\n",
    "            accu = (pred == y).sum().float()\n",
    "\n",
    "        else:                        ## multiclass\n",
    "            y = y.long().to(self.device).reshape(-1)\n",
    "\n",
    "            out = self.model(x, w)\n",
    "            loss = F.cross_entropy(out, y, reduction = 'mean')\n",
    "            loss = loss * self.N_train\n",
    "            loss += self.model.log_prior()\n",
    "\n",
    "            pred = out.max(dim=1, keepdim=False)[1]\n",
    "            accu = (pred == y).sum()\n",
    "\n",
    "        return loss *x.shape[0 ] /self.N_train, accu\n",
    "\n",
    "\n",
    "    def get_nb_parameters(self):\n",
    "        return sum(p.numel() for p in self.model.parameters())\n",
    "\n",
    "\n",
    "    def save_net_weights(self, max_samples):\n",
    "\n",
    "        if len(self.weight_set_samples) >= max_samples:\n",
    "            self.weight_set_samples.pop(0)\n",
    "\n",
    "        self.weight_set_samples.append(copy.deepcopy(self.model.state_dict()))\n",
    "        # print(' saving weight samples %d/%d' % (len(self.weight_set_samples), max_samples) )\n",
    "\n",
    "\n",
    "    def all_sample_eval(self, x, w, y, threshold=0.5):\n",
    "        x = x.to(self.device)\n",
    "        w = w.to(self.device)\n",
    "        y = y.float().to(self.device)\n",
    "\n",
    "        pred = x.new(len(self.weight_set_samples), x.shape[0], self.output_dim)\n",
    "\n",
    "        for i, weight_dict in enumerate(self.weight_set_samples):\n",
    "            self.model.load_state_dict(weight_dict)\n",
    "            out_i = self.model(x, w)\n",
    "            pred[i] = torch.sigmoid(out_i)\n",
    "\n",
    "        pred = (pred.mean(0 ) >threshold).float()\n",
    "        accu = (pred == y).sum().float()\n",
    "\n",
    "        return accu\n",
    "\n",
    "\n",
    "    def save(self, filename):\n",
    "        print('Writting %s\\n' % filename)\n",
    "        torch.save({\n",
    "            'epoch': self.epoch,\n",
    "            'lr': self.lr,\n",
    "            'model': self.model,\n",
    "            'optimizer': self.optimizer,\n",
    "            'scheduler': self.scheduler}, filename)\n",
    "\n",
    "\n",
    "    def load(self, filename):\n",
    "        print('Reading %s\\n' % filename)\n",
    "        state_dict = torch.load(filename)\n",
    "        self.epoch = state_dict['epoch']\n",
    "        self.lr = state_dict['lr']\n",
    "        self.model = state_dict['model']\n",
    "        self.optimizer = state_dict['optimizer']\n",
    "        self.scheduler = state_dict['scheduler']\n",
    "        print('  restoring epoch: %d, lr: %f' % (self.epoch, self.lr))\n",
    "        return self.epoch\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XTCp_4765oXh"
   },
   "source": [
    "## 2. Load Fashion MNIST Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "4aaz_uhP5yaw"
   },
   "outputs": [],
   "source": [
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "f_train = torchvision.datasets.FashionMNIST(root = './data/fmnist', train = True, download = True, transform = transform)\n",
    "f_val = torchvision.datasets.FashionMNIST(root = './data/fmnist', train = False, download = True, transform = transform)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "D57lUkGQ49bo"
   },
   "outputs": [],
   "source": [
    "#robjects.r['load'](\"./index/mnist_idx.RData\")\n",
    "\n",
    "class mydata(Dataset):\n",
    "    def __init__(self, x_list, y_list):\n",
    "        self.x_list = x_list\n",
    "        self.y_list = y_list\n",
    "    def __len__(self):\n",
    "        return len(self.y_list)\n",
    "    def __getitem__(self, i):\n",
    "        x = self.x_list[i].reshape(-1)\n",
    "        w = torch.tensor([1.])\n",
    "        y = torch.tensor([self.y_list[i]])\n",
    "        return (x, w), y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5rv5rQSe59yd"
   },
   "source": [
    "## 3. Stability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "oZK9VcEW6Cv5"
   },
   "outputs": [],
   "source": [
    "\n",
    "def FMNIST_all(c1=3, c2=5, seed=17, act='relu'):\n",
    "\n",
    "    torch.manual_seed(seed)\n",
    "    random.seed(seed)\n",
    "\n",
    "\n",
    "    x_list_c1 = []\n",
    "    y_list_c1 = []\n",
    "    x_list_c2 = []\n",
    "    y_list_c2 = []\n",
    "\n",
    "    for x, y in f_train:\n",
    "        if y == c1:\n",
    "            x_list_c1.append(x)\n",
    "            y_list_c1.append(0)\n",
    "        if y == c2:\n",
    "            x_list_c2.append(x)\n",
    "            y_list_c2.append(1)\n",
    "\n",
    "    n = 5000\n",
    "    x_list = random.sample(x_list_c1, n) + random.sample(x_list_c2, n)\n",
    "    y_list = random.sample(y_list_c1, n) + random.sample(y_list_c2, n)\n",
    "\n",
    "    FashionMNIST_2_train = mydata(x_list, y_list)\n",
    "\n",
    "    ## test set\n",
    "\n",
    "    x_list = []\n",
    "    y_list = []\n",
    "\n",
    "    for x, y in f_val:\n",
    "        if y == c1:\n",
    "            x_list.append(x)\n",
    "            y_list.append(0)\n",
    "        if y == c2:\n",
    "            x_list.append(x)\n",
    "            y_list.append(1)\n",
    "\n",
    "    FashionMNIST_2_test = mydata(x_list, y_list)\n",
    "\n",
    "    n_train = len(FashionMNIST_2_train)\n",
    "    n_test = len(FashionMNIST_2_test)\n",
    "\n",
    "    train_batch_size = 128\n",
    "    test_batch_size = 128\n",
    "\n",
    "    train_loader = DataLoader(FashionMNIST_2_train, batch_size=train_batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(FashionMNIST_2_test, batch_size=test_batch_size, shuffle=True)\n",
    "\n",
    "    grids = GP.GP_generate_grids(d=2, num_grids=28)\n",
    "    phi = GP.GP_eigen_funcs_fast(grids, b=100, poly_degree=30)\n",
    "    phi = np.array(phi)\n",
    "\n",
    "    torch.set_default_dtype(torch.float32)\n",
    "\n",
    "\n",
    "    net = Net(lr=1e-6, input_dim=784, n_hid=128, n_hid2=32, output_dim=1, w_dim=1, n_knots=phi.shape[1],\n",
    "              N_train=2 * n, phi=torch.tensor(phi, dtype=torch.float32), lamb=10, langevin=True,\n",
    "              step_decay_epoch=2000, step_gamma=0.2, act='relu')\n",
    "\n",
    "    epoch = 0\n",
    "    n_epochs=1000\n",
    "\n",
    "    start_save = 3 * n_epochs / 4\n",
    "    save_every = 2\n",
    "    N_saves = 100\n",
    "    test_every = 20\n",
    "    print_every = 100\n",
    "\n",
    "    loss_train = np.zeros(n_epochs)\n",
    "    accu_train = np.zeros(n_epochs)\n",
    "\n",
    "    loss_val = np.zeros(n_epochs)\n",
    "    accu_val = np.zeros(n_epochs)\n",
    "\n",
    "    best_accu = 0\n",
    "\n",
    "\n",
    "    for i in range(epoch, n_epochs):\n",
    "\n",
    "        tic = time.time()\n",
    "        net.scheduler.step()\n",
    "\n",
    "        for (x, w), y in train_loader:\n",
    "            loss, accu = net.fit(x, w, y)\n",
    "            loss_train[i] += loss\n",
    "            accu_train[i] += accu\n",
    "\n",
    "        loss_train[i] /= n_train\n",
    "        accu_train[i] /= n_train\n",
    "        toc = time.time()\n",
    "\n",
    "        if i > start_save and i % save_every == 0:\n",
    "            net.save_net_weights(max_samples=N_saves)\n",
    "    \n",
    "    beta = np.zeros([N_saves, 28*28])\n",
    "    for j, weight_dict in enumerate(net.weight_set_samples):\n",
    "        net.model.load_state_dict(weight_dict)\n",
    "        grad = []\n",
    "        for (x, w), y in train_loader:\n",
    "            x = x.to(device)\n",
    "            x.requires_grad = True\n",
    "            w = w.to(device)\n",
    "            for i in range(x.shape[0]):\n",
    "                log_odds = net.model(x[[i]], w[[i]])\n",
    "                log_odds.sum().backward()\n",
    "            grad.append(copy.deepcopy(x.grad))\n",
    "        grad = torch.cat(grad, axis=0)\n",
    "        beta[j] = (torch.abs(grad).mean(axis=0) > 0.001).numpy()\n",
    "    \n",
    "    return beta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oAgw4QJT7pIT",
    "outputId": "41cc6846-4499-4912-f009-94869bedcec3"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [4:47:38<00:00, 345.17s/it]\n"
     ]
    }
   ],
   "source": [
    "N = 50\n",
    "beta = np.zeros([N, 100, 28*28])\n",
    "for i in tqdm(range(N)):\n",
    "    beta[i] = MNIST_all(c1 = 4, c2 = 7, seed = i)\n",
    "b = b.mean(0)            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "ffqf2qpf6hwa"
   },
   "outputs": [],
   "source": [
    "def plot_threshold(b, thres = 0.7, title = 'MNIST All Data'):\n",
    "\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(10, 5))\n",
    "\n",
    "    im0 = axes[0].imshow(b.reshape(28,28), cmap = 'gray', vmin=0, vmax=1)\n",
    "    axes[0].axis('off')\n",
    "    axes[0].set_title(title)\n",
    "    fig.colorbar(im0, ax =axes[0])\n",
    "\n",
    "    t = b.copy()\n",
    "    t[t>thres] = 1.\n",
    "    t[t<=thres] = 0.\n",
    "\n",
    "    im1 = axes[1].imshow(t.reshape(28,28), cmap = 'gray', vmin=0, vmax=1)\n",
    "    axes[1].axis('off')\n",
    "    axes[1].set_title('Threshold = %s' % thres)\n",
    "    fig.colorbar(im1, ax =axes[1])\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 313
    },
    "id": "97p9BSqv721O",
    "outputId": "835bd644-8c7a-44b2-fb9a-de4b689da137"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_threshold(b=b, thres = 0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "EXe-TiLLnKzZ"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "FashionMNIST_stability.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
