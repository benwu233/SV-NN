{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "p-PldpnA4COC",
    "outputId": "977df2ea-901d-447e-b411-684e31754885"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "R[write to console]: Installing package into ‘/usr/local/lib/R/site-library’\n",
      "(as ‘lib’ is unspecified)\n",
      "\n",
      "R[write to console]: trying URL 'https://cran.rstudio.com/src/contrib/BayesGPfit_0.1.0.tar.gz'\n",
      "\n",
      "R[write to console]: Content type 'application/x-gzip'\n",
      "R[write to console]:  length 26941 bytes (26 KB)\n",
      "\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: \n",
      "\n",
      "R[write to console]: downloaded 26 KB\n",
      "\n",
      "\n",
      "R[write to console]: \n",
      "\n",
      "R[write to console]: \n",
      "R[write to console]: The downloaded source packages are in\n",
      "\t‘/tmp/RtmpqeifBj/downloaded_packages’\n",
      "R[write to console]: \n",
      "R[write to console]: \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import argparse\n",
    "import random\n",
    "import time\n",
    "import os\n",
    "import warnings\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import rpy2.robjects as robjects\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "import torchvision\n",
    "\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from rpy2.robjects.packages import importr\n",
    "from torch.optim.optimizer import Optimizer, required\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "\n",
    "%matplotlib inline\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "## Install R package BayesGPfit\n",
    "\n",
    "utils = importr('utils')\n",
    "utils.install_packages('BayesGPfit', verbose = 0)\n",
    "GP = importr('BayesGPfit')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PZ-1rGV55FNH"
   },
   "source": [
    "## 1. Model\n",
    "\n",
    "### 1.1  BNNSTGP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "gV-55ma34w_u"
   },
   "outputs": [],
   "source": [
    "## BNNSTGP Model\n",
    "\n",
    "class BNNSTGP(nn.Module):\n",
    "    def __init__(self, input_dim, n_hid, output_dim, w_dim, n_knots, phi, lamb=1.,\n",
    "                 b_prior_sig=1, zeta_prior_sig=1, eta_prior_sig=1, alpha_prior_sig=1,\n",
    "                 act = 'relu'):\n",
    "        super(BNNSTGP, self).__init__()\n",
    "\n",
    "        self.input_dim = input_dim\n",
    "        self.n_hid = n_hid\n",
    "        self.output_dim = output_dim\n",
    "        self.w_dim = w_dim\n",
    "        self.n_knots = n_knots\n",
    "        self.phi = phi                            \n",
    "        self.lamb = lamb\n",
    "\n",
    "        self.sigma = nn.Parameter(torch.tensor(1.))\n",
    "        self.b = nn.Parameter(torch.Tensor(n_knots, n_hid).normal_(0, 1))\n",
    "        self.zeta = nn.Parameter(torch.Tensor(n_hid, output_dim).uniform_(-1, 1))\n",
    "        self.eta = nn.Parameter(torch.Tensor(n_hid).zero_())\n",
    "        self.alpha = nn.Parameter(torch.Tensor(w_dim, output_dim).zero_())\n",
    "\n",
    "        self.b_prior_sig = b_prior_sig\n",
    "        self.zeta_prior_sig = zeta_prior_sig\n",
    "        self.eta_prior_sig = eta_prior_sig\n",
    "        self.alpha_prior_sig = alpha_prior_sig\n",
    "\n",
    "        if act == 'relu':\n",
    "            self.act = torch.relu\n",
    "        elif act == 'tanh':\n",
    "            self.act = torch.tanh\n",
    "        elif act == 'sigmoid':\n",
    "            self.act = torch.sigmoid\n",
    "        else:\n",
    "            raise ValueError('Invalid activation function %s' % act)\n",
    "    \n",
    "    def forward(self, x, w):\n",
    "        out = torch.mm(self.phi, self.b)          ## beta_tilde, (p, n_hid)\n",
    "        out = F.threshold(out, self.lamb, self.lamb) - F.threshold(-out, self.lamb, self.lamb)   ## g_lambda\n",
    "        out = self.sigma * out          \n",
    "        out = torch.mm(x, out) + self.eta         ## beta, (N, n_hid)\n",
    "        \n",
    "        out = self.act(out)\n",
    "        out = torch.mm(out, self.zeta) #+ torch.mm(w, self.alpha)\n",
    "\n",
    "        return out\n",
    "    \n",
    "    def log_prior(self):\n",
    "        logprior = 0.5*(self.b**2).sum()/(self.b_prior_sig**2)\n",
    "        logprior += 0.5*(self.zeta**2).sum()/(self.zeta_prior_sig**2)\n",
    "        logprior += 0.5*(self.eta**2).sum()/(self.eta_prior_sig**2)\n",
    "        logprior += 0.5*(self.alpha**2).sum()/(self.alpha_prior_sig**2)\n",
    "        return logprior\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "af3T-9gU5YBo"
   },
   "source": [
    "### 1.2 SGLD "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "-0y0WaOQ5dDf"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "## SGLD (Stochastic Gradient Langevin Dynamics)\n",
    "\n",
    "class SGLD(Optimizer):\n",
    "    def __init__(self, params, lr = required, langevin = True):\n",
    "        self.langevin = langevin\n",
    "        defaults = dict(lr=lr)\n",
    "        super(SGLD, self).__init__(params, defaults)\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def step(self):\n",
    "        loss = None\n",
    "        \n",
    "        for group in self.param_groups:\n",
    "            \n",
    "            for p in group['params']:\n",
    "                if p.grad is None:\n",
    "                    continue\n",
    "                d_p = p.grad\n",
    "                \n",
    "                if self.langevin == True:\n",
    "                    langevin_noise = p.new(p.size()).normal_(mean=0, std=1)/np.sqrt(group['lr'])\n",
    "                    p.add_(0.5*d_p + langevin_noise, alpha = -group['lr'])\n",
    "\n",
    "                else:\n",
    "                    p.add_(0.5*d_p, alpha = -group['lr'])\n",
    "\n",
    "\n",
    "        return loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IAx3l4Nx5iR8"
   },
   "source": [
    "### 1.3 Network Wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "37tPkgQE5kaG"
   },
   "outputs": [],
   "source": [
    "\n",
    "## Network Wrapper\n",
    "\n",
    "class Net(object):\n",
    "\n",
    "    def __init__(self, task='binary', lr=1e-3, input_dim=784, n_hid = 128, output_dim = 1, w_dim = 1, n_knots = 66,\n",
    "                 N_train=200, phi=None, lamb = 1, langevin = True, step_decay_epoch = 100, step_gamma = 0.1, act = 'relu'):\n",
    "        \n",
    "        #print(' Creating Net!! ')\n",
    "        self.task = task\n",
    "        if task not in ['binary', 'multiclass']:\n",
    "            raise ValueError('Invalid task %s' % task)\n",
    "        self.lr = lr\n",
    "\n",
    "        self.input_dim = input_dim\n",
    "        self.n_hid = n_hid\n",
    "        self.output_dim = output_dim\n",
    "        self.w_dim = w_dim\n",
    "        self.n_knots = n_knots\n",
    "        self.phi = phi\n",
    "        self.lamb = lamb\n",
    "        self.act = act\n",
    "\n",
    "        self.N_train = N_train\n",
    "        self.langevin = langevin\n",
    "        self.step_decay_epoch = step_decay_epoch\n",
    "        self.step_gamma = step_gamma\n",
    "\n",
    "        self.create_net()\n",
    "        self.create_opt()\n",
    "        self.epoch = 0\n",
    "        \n",
    "        self.weight_set_samples = []\n",
    "\n",
    "\n",
    "    def create_net(self):\n",
    "        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        self.model = BNNSTGP(input_dim=self.input_dim, n_hid=self.n_hid, output_dim=self.output_dim, \n",
    "                            w_dim=self.w_dim, n_knots = self.n_knots, phi=torch.tensor(self.phi).to(self.device),\n",
    "                            lamb = self.lamb, act = self.act)\n",
    "        self.model.to(self.device)\n",
    "\n",
    "\n",
    "    def create_opt(self):\n",
    "        self.optimizer = SGLD(params=self.model.parameters(), lr=self.lr, langevin = self.langevin)\n",
    "        self.scheduler = StepLR(self.optimizer, step_size = self.step_decay_epoch, gamma=self.step_gamma)\n",
    "\n",
    "\n",
    "    def fit(self, x, w, y, threshold=0.5):\n",
    "        x = x.to(self.device)\n",
    "        w = w.to(self.device)\n",
    "\n",
    "        if self.task == 'binary':\n",
    "            y = y.float().to(self.device).reshape(-1, 1)\n",
    "            self.optimizer.zero_grad()\n",
    "\n",
    "            out = self.model(x, w)\n",
    "            loss = F.binary_cross_entropy_with_logits(out, y, reduction='mean')\n",
    "            loss = loss * self.N_train \n",
    "            #loss += self.model.log_prior()\n",
    "            \n",
    "            loss.backward()\n",
    "            self.optimizer.step() \n",
    "\n",
    "            pred = (torch.sigmoid(out)>threshold).long()\n",
    "            accu = (pred == y.long()).sum().float()\n",
    "\n",
    "        else:                           ## multiclass\n",
    "            y = y.long().to(self.device).reshape(-1)\n",
    "            self.optimizer.zero_grad()\n",
    "\n",
    "            out = self.model(x, w)\n",
    "            loss = F.cross_entropy(out, y, reduction = 'mean')\n",
    "            loss = loss * self.N_train \n",
    "            loss += self.model.log_prior()\n",
    "            \n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "\n",
    "            pred = out.max(dim=1, keepdim=False)[1]\n",
    "            accu = (pred == y).sum()\n",
    "\n",
    "        return loss*x.shape[0]/self.N_train, accu\n",
    "\n",
    "    \n",
    "    def eval(self, x, w, y, threshold=0.5):\n",
    "        x = x.to(self.device)\n",
    "        w = w.to(self.device)\n",
    "        \n",
    "        if self.task == 'binary':\n",
    "            y = y.float().to(self.device).reshape(-1, 1)\n",
    "\n",
    "            out = self.model(x, w)\n",
    "            loss = F.binary_cross_entropy_with_logits(out, y, reduction='mean') \n",
    "            loss = loss * self.N_train \n",
    "            loss += self.model.log_prior()\n",
    "\n",
    "            pred = (torch.sigmoid(out)>threshold).float() \n",
    "            accu = (pred == y).sum().float()\n",
    "\n",
    "        else:                        ## multiclass\n",
    "            y = y.long().to(self.device).reshape(-1)\n",
    "\n",
    "            out = self.model(x, w)\n",
    "            loss = F.cross_entropy(out, y, reduction = 'mean')\n",
    "            loss = loss * self.N_train \n",
    "            loss += self.model.log_prior()\n",
    "\n",
    "            pred = out.max(dim=1, keepdim=False)[1]\n",
    "            accu = (pred == y).sum()\n",
    "\n",
    "        return loss*x.shape[0]/self.N_train, accu\n",
    "    \n",
    "\n",
    "    def get_nb_parameters(self):\n",
    "        return sum(p.numel() for p in self.model.parameters())\n",
    "\n",
    "\n",
    "    def save_net_weights(self, max_samples):\n",
    "        \n",
    "        if len(self.weight_set_samples) >= max_samples:\n",
    "            self.weight_set_samples.pop(0)\n",
    "            \n",
    "        self.weight_set_samples.append(copy.deepcopy(self.model.state_dict()))\n",
    "        #print(' saving weight samples %d/%d' % (len(self.weight_set_samples), max_samples) )\n",
    "\n",
    "\n",
    "    def all_sample_eval(self, x, w, y, threshold=0.5):    \n",
    "        x = x.to(self.device)\n",
    "        w = w.to(self.device)\n",
    "        y = y.float().to(self.device)\n",
    "        \n",
    "        pred = x.new(len(self.weight_set_samples), x.shape[0], self.output_dim)\n",
    "        \n",
    "        for i, weight_dict in enumerate(self.weight_set_samples):\n",
    "            self.model.load_state_dict(weight_dict)\n",
    "            out_i = self.model(x, w)\n",
    "            pred[i] = torch.sigmoid(out_i)\n",
    "            \n",
    "        pred = (pred.mean(0)>threshold).float()\n",
    "        accu = (pred == y).sum().float()\n",
    "\n",
    "        return accu\n",
    "\n",
    "\n",
    "    def save(self, filename):\n",
    "        print('Writting %s\\n' % filename)\n",
    "        torch.save({\n",
    "            'epoch': self.epoch,\n",
    "            'lr': self.lr,\n",
    "            'model': self.model,\n",
    "            'optimizer': self.optimizer,\n",
    "            'scheduler': self.scheduler}, filename)\n",
    "\n",
    "    def load(self, filename):\n",
    "        print('Reading %s\\n' % filename)\n",
    "        state_dict = torch.load(filename)\n",
    "        self.epoch = state_dict['epoch']\n",
    "        self.lr = state_dict['lr']\n",
    "        self.model = state_dict['model']\n",
    "        self.optimizer = state_dict['optimizer']\n",
    "        self.scheduler = state_dict['scheduler']\n",
    "        print('  restoring epoch: %d, lr: %f' % (self.epoch, self.lr))\n",
    "        return self.epoch\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XTCp_4765oXh"
   },
   "source": [
    "## 2. Load MNIST Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "4aaz_uhP5yaw"
   },
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    #transforms.Normalize([0.1307,], [0.3081,])\n",
    "])\n",
    "\n",
    "train = torchvision.datasets.MNIST(root = './data', train = True, download = True, transform = transform)\n",
    "val = torchvision.datasets.MNIST(root = './data', train = False, download = True, transform = transform)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "D57lUkGQ49bo"
   },
   "outputs": [],
   "source": [
    "#robjects.r['load'](\"./index/mnist_idx.RData\")\n",
    "\n",
    "class mydata(Dataset):\n",
    "    def __init__(self, x_list, y_list):\n",
    "        self.x_list = x_list\n",
    "        self.y_list = y_list\n",
    "    def __len__(self):\n",
    "        return len(self.y_list)\n",
    "    def __getitem__(self, i):\n",
    "        x = self.x_list[i].reshape(-1)\n",
    "        w = torch.tensor([1.])\n",
    "        y = torch.tensor([self.y_list[i]])\n",
    "        return (x, w), y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5rv5rQSe59yd"
   },
   "source": [
    "## 3. Stability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "oZK9VcEW6Cv5"
   },
   "outputs": [],
   "source": [
    "def MNIST_all(c1 = 3, c2 = 5, seed = 17):\n",
    "    \n",
    "    torch.manual_seed(seed)\n",
    "    random.seed(seed)\n",
    "\n",
    "    x_list_c1 = []\n",
    "    y_list_c1 = []\n",
    "    x_list_c2 = []\n",
    "    y_list_c2 = []\n",
    "\n",
    "    for x, y in train:\n",
    "        if y==c1:\n",
    "            x_list_c1.append(x)\n",
    "            y_list_c1.append(0)\n",
    "        if y==c2:\n",
    "            x_list_c2.append(x)\n",
    "            y_list_c2.append(1)\n",
    "\n",
    "    n = 5000\n",
    "    x_list = random.sample(x_list_c1, n) + random.sample(x_list_c2, n)\n",
    "    y_list = random.sample(y_list_c1, n) + random.sample(y_list_c2, n)\n",
    "\n",
    "    MNIST_2digit_train = mydata(x_list, y_list)\n",
    "\n",
    "\n",
    "    ## test set\n",
    "\n",
    "    x_list = []\n",
    "    y_list = []\n",
    "\n",
    "    for x, y in val:\n",
    "        if y==c1:\n",
    "            x_list.append(x)\n",
    "            y_list.append(0)\n",
    "        if y==c2:\n",
    "            x_list.append(x)\n",
    "            y_list.append(1)\n",
    "\n",
    "    MNIST_2digit_test = mydata(x_list, y_list)\n",
    "\n",
    "    n_train = len(MNIST_2digit_train)\n",
    "    n_test = len(MNIST_2digit_test)\n",
    "\n",
    "    train_batch_size = 128\n",
    "    test_batch_size = 128\n",
    "\n",
    "    train_loader = DataLoader(MNIST_2digit_train, batch_size=train_batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(MNIST_2digit_test, batch_size=test_batch_size, shuffle=True)\n",
    "\n",
    "    grids = GP.GP_generate_grids(d=2, num_grids=28)\n",
    "    phi = GP.GP_eigen_funcs_fast(grids, b = 100, poly_degree = 20)\n",
    "    phi = np.array(phi)\n",
    "\n",
    "    torch.set_default_dtype(torch.float32)\n",
    "\n",
    "    net = Net(lr=1e-5, input_dim=784, n_hid = 8, output_dim = 1, w_dim = 1, n_knots = phi.shape[1],\n",
    "            N_train=2*n, phi=torch.tensor(phi, dtype=torch.float32), lamb = 9, langevin=True,\n",
    "            step_decay_epoch = 2000, step_gamma = 0.2, act = 'relu')\n",
    "    \n",
    "\n",
    "    epoch = 0\n",
    "    n_epochs = 1000\n",
    "\n",
    "    start_save = 3 * n_epochs / 4\n",
    "    save_every = 2\n",
    "    N_saves = 100\n",
    "    test_every = 20\n",
    "    print_every = 20\n",
    "\n",
    "    loss_train = np.zeros(n_epochs)\n",
    "    accu_train = np.zeros(n_epochs)\n",
    "\n",
    "    loss_val = np.zeros(n_epochs)\n",
    "    accu_val = np.zeros(n_epochs)\n",
    "\n",
    "    best_accu = 0\n",
    "\n",
    "    for i in range(epoch, n_epochs):\n",
    "\n",
    "        tic = time.time()\n",
    "        net.scheduler.step()\n",
    "        \n",
    "        for (x, w), y in train_loader:\n",
    "            loss, accu = net.fit(x, w, y)\n",
    "            loss_train[i] += loss\n",
    "            accu_train[i] += accu\n",
    "\n",
    "            \n",
    "        loss_train[i] /= n_train\n",
    "        accu_train[i] /= n_train\n",
    "        toc = time.time()\n",
    "\n",
    "        if i > start_save and i % save_every == 0:\n",
    "            net.save_net_weights(max_samples = N_saves)\n",
    "\n",
    "    beta = np.zeros([N_saves, 28*28])\n",
    "    for j, weight_dict in enumerate(net.weight_set_samples):\n",
    "        net.model.load_state_dict(weight_dict)\n",
    "        grad = []\n",
    "        for (x, w), y in train_loader:\n",
    "            x = x.to(device)\n",
    "            x.requires_grad = True\n",
    "            w = w.to(device)\n",
    "            for i in range(x.shape[0]):\n",
    "                log_odds = net.model(x[[i]], w[[i]])\n",
    "                log_odds.sum().backward()\n",
    "            grad.append(copy.deepcopy(x.grad))\n",
    "        grad = torch.cat(grad, axis=0)\n",
    "        beta[j] = (torch.abs(grad).mean(axis=0) > 0.001).numpy()\n",
    "    \n",
    "    return beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oAgw4QJT7pIT",
    "outputId": "2e166819-debc-4a9a-ae55-a095bc7a694d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [5:57:50<00:00, 429.42s/it]\n"
     ]
    }
   ],
   "source": [
    "N = 50\n",
    "beta = np.zeros([N, 100, 28*28])\n",
    "for i in tqdm(range(N)):\n",
    "    beta[i] = MNIST_all(c1 = 4, c2 = 7, seed = i)\n",
    "b = b.mean(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j, weight_dict in enumerate(net.weight_set_samples):\n",
    "    net.model.load_state_dict(weight_dict)\n",
    "    grad = []\n",
    "    for (x, w), y in train_loader:\n",
    "        x = x.to(device)\n",
    "        x.requires_grad = True\n",
    "        w = w.to(device)\n",
    "        for i in range(x.shape[0]):\n",
    "            log_odds = net.model(x[[i]], w[[i]])\n",
    "            log_odds.sum().backward()\n",
    "        grad.append(copy.deepcopy(x.grad))\n",
    "    grad = torch.cat(grad, axis=0)\n",
    "    beta[seed, j] = (torch.abs(grad).mean(axis=0) > 0.001).numpy()\n",
    "\n",
    "b = beta.mean(axis=1)\n",
    "np.save(f'../save_model/b_{lamb}.npy', b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "ffqf2qpf6hwa"
   },
   "outputs": [],
   "source": [
    "def plot_threshold(b, thres = 0.7, title = 'MNIST All Data'):\n",
    "\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(10, 5))\n",
    "\n",
    "    im0 = axes[0].imshow(b.reshape(28,28), cmap = 'gray', vmin=0, vmax=1)\n",
    "    axes[0].axis('off')\n",
    "    axes[0].set_title(title)\n",
    "    fig.colorbar(im0, ax =axes[0])\n",
    "\n",
    "    t = b.copy()\n",
    "    t[t>thres] = 1.\n",
    "    t[t<=thres] = 0.\n",
    "\n",
    "    im1 = axes[1].imshow(t.reshape(28,28), cmap = 'gray', vmin=0, vmax=1)\n",
    "    axes[1].axis('off')\n",
    "    axes[1].set_title('Threshold = %s' % thres)\n",
    "    fig.colorbar(im1, ax =axes[1])\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 313
    },
    "id": "97p9BSqv721O",
    "outputId": "d7788194-c56c-4521-8390-4257354dac55"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_threshold(b=b, thres = 0.7)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "MNIST_stability.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
